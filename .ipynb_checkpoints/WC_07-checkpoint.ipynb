{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly Challenge 07\n",
    "\n",
    "*Original URL* https://community.alteryx.com/t5/Weekly-Challenge/Challenge-7-Download-Data-and-Parse-JSON/td-p/36734 and [**My Alteryx Approach**](https://github.com/dsmdavid/Alteryx-Weekly-Challenge/tree/master/submitted/sub_Challenge%2307)\n",
    "\n",
    "## Brief\n",
    "\n",
    "For the seventh challenge letâ€™s look at downloading data with an API and parsing that data from JSON into a usable format.\n",
    "\n",
    "The data we will use comes from Quandl. The Quandl site offers access to several million financial, economic and social datasets. Data is indexed from multiple sources allowing users to find and download in various formats. All Quandl's data are accessible via an API.\n",
    "\n",
    "For this example the response from these APIs is JSON. Our user is trying to get aggregated Annual Outbound Tourism Statistics for the US dating back to 1995. The Text Input contains the URL for the API request. Your goal is to parse the response.\n",
    "\n",
    "Hint: After parsing the JSON, you will need to further identify the patterns within the data to effectively stage into a table for analytics.\n",
    "\n",
    "Note: The data in the API is subject to change. When trying to match the output, the effort should be focused on achieving an identically structured dataset. \n",
    "\n",
    "We have listed this as an advanced challenge since configuring the download tool and parsing functions are more advanced topics. We are looking forward to hearing your feedback.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach I want to follow:\n",
    "1. Download the data.\n",
    "1. Get the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_api = r'https://www.quandl.com/api/v3/datasets/UTOR/EXTUR_USA.json?api_key=5aMivNdsRkZNB-afkjse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Download the data using requests, then get the dataframe from the json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'id': 32422254,\n",
       "  'dataset_code': 'EXTUR_USA',\n",
       "  'database_code': 'UTOR',\n",
       "  'name': 'Outbound Tourism - United States of America',\n",
       "  'description': 'Outbound tourism statistics for United States of America.  Includes departures from United States of America in thousands, and tourism expenditures in other countries in USD millions.  Source: World Tourism Organization compendia and yearbooks.',\n",
       "  'refreshed_at': '2018-11-24T03:15:52.556Z',\n",
       "  'newest_available_date': '2014-12-31',\n",
       "  'oldest_available_date': '1995-12-31',\n",
       "  'column_names': ['Date',\n",
       "   'Departures - Thousands',\n",
       "   'Tourism expenditure in other countries - US$ Mn',\n",
       "   'Travel - US$ Mn',\n",
       "   'Passenger transport - US$ Mn'],\n",
       "  'frequency': 'annual',\n",
       "  'type': 'Time Series',\n",
       "  'premium': False,\n",
       "  'limit': None,\n",
       "  'transform': None,\n",
       "  'column_index': None,\n",
       "  'start_date': '1995-12-31',\n",
       "  'end_date': '2014-12-31',\n",
       "  'data': [['2014-12-31', 68303.0, 145678.0, 110788.0, 34890.0],\n",
       "   ['2013-12-31', 61874.0, 136136.0, 104107.0, 32029.0],\n",
       "   ['2012-12-31', 60697.0, 129902.0, 100337.0, 29565.0],\n",
       "   ['2011-12-31', 59209.0, 116448.0, 89701.0, 26747.0],\n",
       "   ['2010-12-31', 61061.0, 110049.0, 86623.0, 23426.0],\n",
       "   ['2009-12-31', 62051.0, 102953.0, 81421.0, 21532.0],\n",
       "   ['2008-12-31', 63653.0, 119838.0, 92546.0, 27292.0],\n",
       "   ['2007-12-31', 64049.0, 112788.0, 89235.0, 23553.0],\n",
       "   ['2006-12-31', 63663.0, 106848.0, 84206.0, 22642.0],\n",
       "   ['2005-12-31', 63503.0, 101421.0, 79990.0, 21431.0],\n",
       "   ['2004-12-31', 61809.0, 94764.0, 71034.0, 23730.0],\n",
       "   ['2003-12-31', 56250.0, 82091.0, 61966.0, 20125.0],\n",
       "   ['2002-12-31', 58066.0, 81860.0, 62671.0, 19189.0],\n",
       "   ['2001-12-31', 59442.0, 85610.0, 63689.0, 21921.0],\n",
       "   ['2000-12-31', 61327.0, 91473.0, 67860.0, 23613.0],\n",
       "   ['1999-12-31', 57222.0, 82513.0, 61567.0, 20946.0],\n",
       "   ['1998-12-31', 55696.0, 78423.0, 58451.0, 19972.0],\n",
       "   ['1997-12-31', 53229.0, 71948.0, 53808.0, 18140.0],\n",
       "   ['1996-12-31', 52999.0, 65477.0, 49672.0, 15805.0],\n",
       "   ['1995-12-31', 51285.0, 61042.0, 46379.0, 14663.0]],\n",
       "  'collapse': None,\n",
       "  'order': None,\n",
       "  'database_id': 13151}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = requests.get(url_api)\n",
    "test.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = pd.DataFrame.from_records(test.json()['dataset']['data'], columns = test.json()['dataset']['column_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Use just pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a temporary df to download the data\n",
    "df1 = pd.read_json(url_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## keep only the fields of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = pd.DataFrame.from_records(df1.loc[\"data\"][0],columns = df1.loc[\"column_names\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A & B  are equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                                               True\n",
       "Departures - Thousands                             True\n",
       "Tourism expenditure in other countries - US$ Mn    True\n",
       "Travel - US$ Mn                                    True\n",
       "Passenger transport - US$ Mn                       True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_a == df_b).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
